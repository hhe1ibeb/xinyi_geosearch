{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Roads Data and Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get roads in xinyi district \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "xls = pd.ExcelFile(\"./tw_raods.xls\")\n",
    "\n",
    "sheetX = xls.parse(0) #2 is the sheet number+1 thus if the file has only 1 sheet write 0 in paranthesis\n",
    "\n",
    "town_names = sheetX['TownName']\n",
    "county_id = sheetX['CountyID']\n",
    "road_names = sheetX['RoadName']\n",
    "\n",
    "xinyi_roads = []\n",
    "\n",
    "id = 0\n",
    "for town in town_names:\n",
    "    if town == \"信義區\" and county_id[id] == \"A\":\n",
    "        xinyi_roads.append(road_names[id])\n",
    "        print(road_names[id])\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions for encoding and decoding\n",
    "\n",
    "from pyproj import Proj, Transformer\n",
    "\n",
    "# Define the projections for TWD97 TM2 121 and WGS84 using the new syntax\n",
    "proj_twd97 = Proj('epsg:3826')  # TWD97 TM2 121 projection\n",
    "proj_wgs84 = Proj('epsg:4326')  # WGS84 projection\n",
    "\n",
    "# Create a Transformer object for the conversion\n",
    "transformer = Transformer.from_proj(proj_twd97, proj_wgs84)\n",
    "\n",
    "def twd97_to_wgs84(x, y):\n",
    "    # Transform the coordinates from TWD97 to WGS84 using the Transformer object\n",
    "    lon, lat = transformer.transform(x, y)\n",
    "    return lat, lon\n",
    "\n",
    "def decode(encoded_str):\n",
    "    # Assuming the encoded_str is exactly 8 characters as per your encoding scheme\n",
    "    # Define the reversed dictionary for decoding\n",
    "    decoding_dict = {\n",
    "        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7,\n",
    "        '8': 8, '9': 9, 'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14,\n",
    "        'F': 15, 'G': 16, 'H': 17, 'J': 18, 'K': 19, 'L': 20, 'M': 21,\n",
    "        'N': 22, 'P': 23, 'Q': 24, 'R': 25, 'S': 26, 'T': 27, 'U': 28,\n",
    "        'V': 29, 'W': 30, 'X': 31\n",
    "    }  # Fill in with the reversed mappings\n",
    "\n",
    "    # Split the encoded string into X and Y components\n",
    "    encoded_x = encoded_str[:4]\n",
    "    encoded_y = encoded_str[4:]\n",
    "\n",
    "    # Pad the Y component to 7 characters\n",
    "    # encoded_y_padded = encoded_y.ljust(7, '0')\n",
    "\n",
    "    # Decode each component\n",
    "    x = 0\n",
    "    for i, char in enumerate(reversed(encoded_x)):\n",
    "        x += decoding_dict[char] * (32 ** i)\n",
    "\n",
    "    y = 0\n",
    "    for i, char in enumerate(reversed(encoded_y)):\n",
    "        y += decoding_dict[char] * (32 ** i)\n",
    "    \n",
    "    # Add 2,000,000 to the Y component\n",
    "    y += 2000000\n",
    "    lon, lat = transformer.transform(x, y)\n",
    "    return lon, lat\n",
    "\n",
    "# Example usage of the function with decoded coordinates\n",
    "x, y = decode(\"95ELPFWG\")  # Use the decode function you provided earlier\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start and end pos on road found\n",
    "import csv\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "file_path = './Section.xml'\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "namespace = {'ns': 'http://traffic.transportdata.tw/standard/traffic/schema/'}\n",
    "\n",
    "sections = root.find('ns:Sections', namespace)\n",
    "\n",
    "section_pos = []\n",
    "\n",
    "loaded_roads = []\n",
    "\n",
    "if sections is not None:\n",
    "    for section in sections:\n",
    "        road_section = section.find('.//ns:RoadSection', namespace)\n",
    "\n",
    "        if road_section is not None:\n",
    "            section_start = road_section.find('.//ns:Start', namespace).text\n",
    "            section_end = road_section.find('.//ns:End', namespace).text\n",
    "\n",
    "        road_information = {\n",
    "            'SectionID': section.find('ns:SectionID', namespace).text,\n",
    "            'SectionName': section.find('ns:SectionName', namespace).text,\n",
    "            'RoadID': section.find('ns:RoadID', namespace).text,\n",
    "            'RoadName': section.find('ns:RoadName', namespace).text,\n",
    "            'RoadClass': section.find('ns:RoadClass', namespace).text,\n",
    "            'RoadDirection': section.find('ns:RoadDirection', namespace).text,\n",
    "            'SectionLength': section.find('ns:SectionLength', namespace).text,\n",
    "            'RoadSectionStart': section_start,\n",
    "            'RoadSectionEnd': section_end\n",
    "        }\n",
    "        if(road_information['RoadName'] in xinyi_roads):\n",
    "            loaded_roads.append(road_information['RoadName'])\n",
    "            section_pos.append([decode(section_start), decode(section_end)])\n",
    "            print(road_information['RoadName'], decode(section_start), decode(section_end))\n",
    "\n",
    "with open('./roads_all.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['RoadName', 'Start', 'End'])\n",
    "    for i in range(len(loaded_roads)):\n",
    "        writer.writerow([loaded_roads[i], section_pos[i][0], section_pos[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_MAPS_API_KEY = os.environ.get('GOOGLE_MAPS_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "from geopy.distance import geodesic\n",
    "from streetview import search_panoramas\n",
    "from streetview import get_streetview\n",
    "import googlemaps\n",
    "import polyline\n",
    "from shapely.geometry import LineString\n",
    "import json\n",
    "import re\n",
    "\n",
    "def get_address_from_coordinates(latitude, longitude):\n",
    "    # Google Maps Geocoding API endpoint\n",
    "    endpoint = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    \n",
    "    # Your API key (you need to get one from the Google Cloud Console and enable the Geocoding API)\n",
    "    api_key = GOOGLE_MAPS_API_KEY\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"latlng\": f\"{latitude}, {longitude}\",\n",
    "        \"key\": api_key\n",
    "    }\n",
    "\n",
    "    # Send the request and get the response\n",
    "    response = requests.get(endpoint, params=params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the result\n",
    "        results = response.json()['results']\n",
    "        if results:\n",
    "            # Return the first result (the most relevant address)\n",
    "            return results[0]['formatted_address']\n",
    "        else:\n",
    "            return \"No address found for these coordinates.\"\n",
    "    else:\n",
    "        return \"Failed to retrieve data.\"\n",
    "    \n",
    "def interpolate_points(start, end, interval_meters):\n",
    "    distance = geodesic(start, end).meters\n",
    "    num_intervals = int(math.ceil(distance / interval_meters))\n",
    "    interpolated_points = [start]\n",
    "    for i in range(1, num_intervals):\n",
    "        fraction = i / num_intervals\n",
    "        interpolated_point = geodesic(kilometers=fraction * (distance / 1000)).destination(start, calculate_heading(*start, *end))\n",
    "        interpolated_points.append((interpolated_point.latitude, interpolated_point.longitude))\n",
    "    interpolated_points.append(end)\n",
    "    return interpolated_points\n",
    "\n",
    "def calculate_heading(lat1, lon1, lat2, lon2):\n",
    "    # convert latitude and longitude to radians\n",
    "    lat1, lon1, lat2, lon2 = [math.radians(x) for x in [lat1, lon1, lat2, lon2]]\n",
    "\n",
    "    # calculate the difference between the longitudes\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # calculate the heading using the Haversine formula\n",
    "    y = math.sin(dlon) * math.cos(lat2)\n",
    "    x = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(\n",
    "        dlon\n",
    "    )\n",
    "    heading = math.degrees(math.atan2(y, x))\n",
    "\n",
    "    # normalize the heading to a value between 0 and 360 degrees\n",
    "    if heading < 0:\n",
    "        heading += 360\n",
    "\n",
    "    return heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_distance = 30  # Example distance\n",
    "\n",
    "coordinates_list = []\n",
    "\n",
    "for pos in section_pos:\n",
    "    origin = get_address_from_coordinates(pos[0][0], pos[0][1])\n",
    "    destination = get_address_from_coordinates(pos[1][0], pos[1][1])\n",
    "\n",
    "    gmaps = googlemaps.Client(key=GOOGLE_MAPS_API_KEY)\n",
    "\n",
    "    pattern = r'\\bXinyi District, Taipei City, Taiwan \\d{3}\\b'\n",
    "    directions_result = gmaps.directions(pos[0], pos[1], mode=\"driving\")\n",
    "    polyline_str = directions_result[0][\"overview_polyline\"][\"points\"]\n",
    "    coords = polyline.decode(polyline_str)\n",
    "    line = LineString(coords)\n",
    "    simplified_line = line.simplify(tolerance=0, preserve_topology=False)\n",
    "    simplified_coords = list(simplified_line.coords)\n",
    "\n",
    "    final_coords = []\n",
    "\n",
    "    # Interpolate points along the route at the specified distance intervals\n",
    "    for i in range(len(simplified_coords) - 1):\n",
    "        start_coord = simplified_coords[i]\n",
    "        end_coord = simplified_coords[i + 1]\n",
    "        final_coords.extend(interpolate_points(start_coord, end_coord, desired_distance))\n",
    "\n",
    "    for i in range(len(final_coords) - 1):\n",
    "        pos1 = final_coords[i]\n",
    "        pos2 = final_coords[i + 1]\n",
    "        lat, lon = pos1[0], pos1[1]\n",
    "        heading = calculate_heading(pos1[0], pos1[1], pos2[0], pos2[1])\n",
    "\n",
    "        addr = get_address_from_coordinates(lat, lon)\n",
    "\n",
    "        if re.search(pattern, addr):\n",
    "            print(addr)\n",
    "            coordinates_list.append({\"latitude\": lat, \"longitude\": lon, \"heading\": heading})\n",
    "            \n",
    "json_file_path = os.path.join(\"./\", \"coordinates_list.json\")\n",
    "\n",
    "# Write the coordinates list to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(coordinates_list, json_file, indent=4)\n",
    "\n",
    "print(f\"Coordinates have been saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Street View Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('coordinates_list.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "# look forward\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_fwd.jpg\"\n",
    "    filepath = os.path.join(\"./images_fwd\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('coordinates_list.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "# look right\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading+90,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_r.jpg\"\n",
    "    filepath = os.path.join(\"./images_right\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('coordinates_list.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "# look left\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading-90,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_l.jpg\"\n",
    "    filepath = os.path.join(\"./images_left\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "roads = set()\n",
    "repeated = set()\n",
    "new_roads = set()\n",
    "\n",
    "with open('./roads_all.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    line_count = 0\n",
    "    for row in reader:\n",
    "        if line_count == 0: \n",
    "            line_count += 1 \n",
    "            continue\n",
    "        roads.add(row[0])\n",
    "        line_count += 1 \n",
    "\n",
    "with open('./small_streets.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    line_count = 0\n",
    "    for row in reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        if row[0] not in roads:\n",
    "            new_roads.add(row[0])\n",
    "        else:\n",
    "            repeated.add(row[0])\n",
    "        line_count += 1\n",
    "\n",
    "df = pd.read_csv('./small_streets.csv')\n",
    "for road in repeated:\n",
    "    df = df.drop(df[df.Name == road].index)\n",
    "    df.to_csv('./small_streets.csv', index=False)\n",
    "\n",
    "print(roads)\n",
    "print(repeated)\n",
    "print(new_roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from streetview import search_panoramas\n",
    "from streetview import get_streetview\n",
    "import googlemaps\n",
    "import polyline\n",
    "from shapely.geometry import LineString\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "desired_distance = 30  # Example distance\n",
    "\n",
    "coordinates_list = []\n",
    "\n",
    "section_pos = []\n",
    "\n",
    "with open('./small_streets.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    line_count = 0\n",
    "    for row in reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        start = [row[1].split(',')][0]\n",
    "        end = [row[2].split(',')][0]\n",
    "        section_pos.append([start, end])\n",
    "        line_count += 1\n",
    "\n",
    "for pos in section_pos:\n",
    "    origin = get_address_from_coordinates(pos[0][0], pos[0][1])\n",
    "    destination = get_address_from_coordinates(pos[1][0], pos[1][1])\n",
    "\n",
    "    gmaps = googlemaps.Client(key=GOOGLE_MAPS_API_KEY)\n",
    "\n",
    "    pattern = r'\\bXinyi District, Taipei City, Taiwan \\d{3}\\b'\n",
    "    directions_result = gmaps.directions(pos[0], pos[1], mode=\"driving\")\n",
    "    polyline_str = directions_result[0][\"overview_polyline\"][\"points\"]\n",
    "    coords = polyline.decode(polyline_str)\n",
    "    line = LineString(coords)\n",
    "    simplified_line = line.simplify(tolerance=0, preserve_topology=False)\n",
    "    simplified_coords = list(simplified_line.coords)\n",
    "\n",
    "    final_coords = []\n",
    "\n",
    "    for i in range(len(simplified_coords) - 1):\n",
    "        start_coord = simplified_coords[i]\n",
    "        end_coord = simplified_coords[i + 1]\n",
    "        final_coords.extend(interpolate_points(start_coord, end_coord, desired_distance))\n",
    "\n",
    "    for i in range(len(final_coords) - 1):\n",
    "        pos1 = final_coords[i]\n",
    "        pos2 = final_coords[i + 1]\n",
    "        lat, lon = pos1[0], pos1[1]\n",
    "        heading = calculate_heading(pos1[0], pos1[1], pos2[0], pos2[1])\n",
    "\n",
    "        addr = get_address_from_coordinates(lat, lon)\n",
    "\n",
    "        if re.search(pattern, addr):\n",
    "            print(addr)\n",
    "\n",
    "            coordinates_list.append({\"latitude\": lat, \"longitude\": lon, \"heading\": heading})\n",
    "\n",
    "json_file_path = os.path.join(\"./\", \"small_streets.json\")\n",
    "\n",
    "# Write the coordinates list to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(coordinates_list, json_file, indent=4)\n",
    "\n",
    "print(f\"Coordinates have been saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('small_streets.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "# look forward\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_fwd.jpg\"\n",
    "    filepath = os.path.join(\"./small_streets/images_fwd\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('small_streets.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "# look right\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading+90,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_r.jpg\"\n",
    "    filepath = os.path.join(\"./small_streets/images_right\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('small_streets.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "# look left\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading-90,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_l.jpg\"\n",
    "    filepath = os.path.join(\"./small_streets/images_left\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_distance = 30  # Example distance\n",
    "\n",
    "coordinates_list = []\n",
    "\n",
    "section_pos = []\n",
    "\n",
    "with open('./super_small_streets.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    line_count = 0\n",
    "    for row in reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        start = [row[1].split(',')][0]\n",
    "        end = [row[2].split(',')][0]\n",
    "        section_pos.append([start, end])\n",
    "        line_count += 1\n",
    "\n",
    "for pos in section_pos:\n",
    "    origin = get_address_from_coordinates(pos[0][0], pos[0][1])\n",
    "    destination = get_address_from_coordinates(pos[1][0], pos[1][1])\n",
    "\n",
    "    gmaps = googlemaps.Client(key=GOOGLE_MAPS_API_KEY)\n",
    "\n",
    "    pattern = r'\\bXinyi District, Taipei City, Taiwan \\d{3}\\b'\n",
    "    directions_result = gmaps.directions(pos[0], pos[1], mode=\"driving\")\n",
    "    polyline_str = directions_result[0][\"overview_polyline\"][\"points\"]\n",
    "    coords = polyline.decode(polyline_str)\n",
    "    line = LineString(coords)\n",
    "    simplified_line = line.simplify(tolerance=0, preserve_topology=False)\n",
    "    simplified_coords = list(simplified_line.coords)\n",
    "\n",
    "    final_coords = []\n",
    "\n",
    "    for i in range(len(simplified_coords) - 1):\n",
    "        start_coord = simplified_coords[i]\n",
    "        end_coord = simplified_coords[i + 1]\n",
    "        final_coords.extend(interpolate_points(start_coord, end_coord, desired_distance))\n",
    "\n",
    "    for i in range(len(final_coords) - 1):\n",
    "        pos1 = final_coords[i]\n",
    "        pos2 = final_coords[i + 1]\n",
    "        lat, lon = pos1[0], pos1[1]\n",
    "        heading = calculate_heading(pos1[0], pos1[1], pos2[0], pos2[1])\n",
    "\n",
    "        addr = get_address_from_coordinates(lat, lon)\n",
    "\n",
    "        if re.search(pattern, addr):\n",
    "            print(addr)\n",
    "\n",
    "            coordinates_list.append({\"latitude\": lat, \"longitude\": lon, \"heading\": heading})\n",
    "\n",
    "json_file_path = os.path.join(\"./\", \"super_small_streets.json\")\n",
    "\n",
    "# Write the coordinates list to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(coordinates_list, json_file, indent=4)\n",
    "\n",
    "print(f\"Coordinates have been saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import json\n",
    "\n",
    "# Load your JSON data\n",
    "with open('./big_roads.json', 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open('./small_streets.json', 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "with open('./super_small_streets.json', 'r') as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "# Create a base map\n",
    "# Note: Change latitude and longitude to your desired starting point and adjust zoom_start as needed\n",
    "map = folium.Map(location=[25.032444, 121.572403], zoom_start=14.25)\n",
    "\n",
    "# Function to add coordinates from a list to the map\n",
    "def plot_coordinates(data, map_object, marker_color='blue'):\n",
    "    for coord in data:\n",
    "        folium.Marker(\n",
    "            location=[coord['latitude'], coord['longitude']],\n",
    "            icon=folium.Icon(color=marker_color),\n",
    "        ).add_to(map_object)\n",
    "\n",
    "# Plot coordinates from both JSON files\n",
    "plot_coordinates(data1, map, 'blue')\n",
    "plot_coordinates(data2, map, 'red')\n",
    "plot_coordinates(data3, map, 'green')\n",
    "\n",
    "# Save or display the map\n",
    "map.save('map_v2.html')\n",
    "# Or use map to display inline if using Jupyter Notebook\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from streetview import search_panoramas, get_streetview\n",
    "\n",
    "f = open('super_small_streets.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "for i in data:\n",
    "    lat = i['latitude']\n",
    "    lon = i['longitude']\n",
    "    heading = i['heading']\n",
    "    print(lat, lon)\n",
    "\n",
    "    panoids = search_panoramas(lat, lon)\n",
    "    pano = panoids[-1]\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_fwd.jpg\"\n",
    "    filepath = os.path.join(\"./super_small_street/images_fwd\", filename)\n",
    "    image.save(filepath, \"jpeg\")\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading+90,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_r.jpg\"\n",
    "    filepath = os.path.join(\"./super_small_street/images_r\", filename)\n",
    "    image.save(filepath, \"jpeg\")\n",
    "\n",
    "    image = get_streetview(\n",
    "        pano.pano_id, GOOGLE_MAPS_API_KEY, 600, 600, heading-90,\n",
    "    )\n",
    "\n",
    "    filename = f\"{lat}_{lon}_l.jpg\"\n",
    "    filepath = os.path.join(\"./super_small_street/images_l\", filename)\n",
    "    image.save(filepath, \"jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Coordinates to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def extract_coordinates(filename):\n",
    "    base_name = filename[:-3:]\n",
    "    coordinate = '_'.join(base_name.split('_')[:2])\n",
    "    return coordinate\n",
    "\n",
    "def record_coordinates(folder_path, output_file='coordinates.csv'):\n",
    "    try:\n",
    "        # Set to store unique coordinates\n",
    "        unique_coordinates = set()\n",
    "\n",
    "        # Walk through the directory\n",
    "        for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                coordinate = extract_coordinates(filename)\n",
    "                print(coordinate)\n",
    "                unique_coordinates.add(coordinate)\n",
    "\n",
    "        # Write the unique coordinates to the CSV file\n",
    "        with open(output_file, 'w', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(['lat', 'lon'])\n",
    "\n",
    "            for coordinate in sorted(unique_coordinates):\n",
    "                lat, lon = coordinate.split('_')\n",
    "                csvwriter.writerow([lat, lon])\n",
    "        \n",
    "        print(f\"Coordinates have been recorded in {output_file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'your_folder_path' with the path to your folder\n",
    "folder_path = './photos'\n",
    "record_coordinates(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Photos URL to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_image_url(lat, lon):\n",
    "    fwd = \"https://github.com/hhe1ibeb/xinyi_geosearch/blob/dev/data/photos/\" + str(lat) + \"_\" + str(lon) + \"_fwd.jpeg?raw=true\"\n",
    "    l = \"https://github.com/hhe1ibeb/xinyi_geosearch/blob/dev/data/photos/\" + str(lat) + \"_\" + str(lon) + \"_l.jpeg?raw=true\"\n",
    "    r = \"https://github.com/hhe1ibeb/xinyi_geosearch/blob/dev/data/photos/\" + str(lat) + \"_\" + str(lon) + \"_r.jpeg?raw=true\" \n",
    "    return [fwd, l, r]\n",
    "\n",
    "df = pd.read_csv('coordinates.csv')\n",
    "\n",
    "for index in range(len(df)):\n",
    "    lat = df['lat'][index]\n",
    "    lon = df['lon'][index]\n",
    "    urls = get_image_url(lat, lon)\n",
    "    df.at[index, 'fwd'] = urls[0]\n",
    "    df.at[index, 'l'] = urls[1]\n",
    "    df.at[index, 'r'] = urls[2]\n",
    "\n",
    "df.to_csv('coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '../coordinates_translated.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define a function to extract lat and lon from URL and convert to string\n",
    "def extract_coordinates(url):\n",
    "    match = re.search(r'/([\\d.]+)_([\\d.]+)_', url)\n",
    "    if match:\n",
    "        return str(match.group(1)), str(match.group(2))\n",
    "    return None, None\n",
    "\n",
    "coordinates = data['fwd'].apply(extract_coordinates)\n",
    "data['lat'] = coordinates.apply(lambda x: x[0] if x else None)\n",
    "data['lon'] = coordinates.apply(lambda x: x[1] if x else None)\n",
    "\n",
    "# Ensure columns are explicitly set to string type\n",
    "data['lat'] = data['lat'].astype(str)\n",
    "data['lon'] = data['lon'].astype(str)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = '../coordinates_translated_safe.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Updated file saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_lat_lon_strings(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'lat' and 'lon' columns are strings\n",
    "    not_string_rows = []\n",
    "    for index, row in data.iterrows():\n",
    "        if not isinstance(row['lat'], str) or not isinstance(row['lon'], str):\n",
    "            not_string_rows.append((index, row['lat'], row['lon']))\n",
    "    \n",
    "    # Print results\n",
    "    if not_string_rows:\n",
    "        print(\"Rows where 'lat' or 'lon' are not strings:\")\n",
    "        for row in not_string_rows:\n",
    "            print(f\"Row {row[0]}: lat = {row[1]}, lon = {row[2]}\")\n",
    "    else:\n",
    "        print(\"'lat' and 'lon' columns are strings in all rows.\")\n",
    "\n",
    "# Replace 'path_to_your_file/coordinates_translated.csv' with the path to your CSV file\n",
    "file_path = '../coordinates_translated_safe.csv'\n",
    "check_lat_lon_strings(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
