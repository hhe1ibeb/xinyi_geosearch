{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets pandas pymongo sentence_transformers\n",
    "%pip install -U transformers\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"hhe1ibeb/xinyi_geodata\")\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "dataset_df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Remove data point where plot coloumn is missing\n",
    "dataset_df = dataset_df.dropna(subset=\"description\")\n",
    "print(\"\\nNumber of missing values in each column after removal:\")\n",
    "print(dataset_df.isnull().sum())\n",
    "\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# https://huggingface.co/thenlper/gte-large\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.encode(text)\n",
    "\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[\"embedding\"] = dataset_df[\"description\"].apply(get_embedding)\n",
    "\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import os\n",
    "\n",
    "def get_mongo_client(mongo_uri):\n",
    "    \"\"\"Establish connection to the MongoDB.\"\"\"\n",
    "    try:\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "        print(\"Connection to MongoDB successful\")\n",
    "        return client\n",
    "    except pymongo.errors.ConnectionFailure as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "if not mongo_uri:\n",
    "    print(\"MONGO_URI not set in environment variables\")\n",
    "\n",
    "mongo_client = get_mongo_client(mongo_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ingest data into MongoDB\n",
    "db = mongo_client[\"xinyi_geodata\"]\n",
    "collection = db[\"collection_1\"]\n",
    "# Delete any existing records in the collection\n",
    "# collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Define Schema\n",
    "class Coord(BaseModel):\n",
    "    lat: float\n",
    "    lon: float\n",
    "    description: str\n",
    "\n",
    "\n",
    "async def get_coord(lat: float, lon: float):\n",
    "    item = await collection.find_one({\"lat\":lat, \"lon\":lon})\n",
    "    if item:\n",
    "        return item\n",
    "    return None\n",
    "\n",
    "get_coord(25.03334, 121.58122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dataset_df.to_dict(\"records\")\n",
    "# collection.insert_many(documents)\n",
    "\n",
    "# print(\"Data ingestion into MongoDB completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(user_query, collection):\n",
    "    \"\"\"\n",
    "    Perform a vector search in the MongoDB collection based on the user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "    collection (MongoCollection): The MongoDB collection to search.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of matching documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embedding for the user query\n",
    "    query_embedding = get_embedding(user_query)\n",
    "\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "\n",
    "    # Define the vector search pipeline\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"embedding\",\n",
    "                \"numCandidates\": 150,  # Number of candidate matches to consider\n",
    "                \"limit\": 4,  # Return top 4 matches\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,  # Exclude the _id field\n",
    "                \"lat\": 1,  # Include the lat field\n",
    "                \"lon\": 1,  # Include the lon field\n",
    "                \"description\": 1,  # Include the description field\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},  # Include the search score\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the search\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result(query, collection):\n",
    "\n",
    "    get_knowledge = vector_search(query, collection)\n",
    "\n",
    "    search_result = \"\"\n",
    "    for result in get_knowledge:\n",
    "        search_result += f\"Lat: {result.get('lat', 'N/A')}, Lon: {result.get('lon', 'N/A')}, Description: {result.get('description', 'N/A')}\\n\"\n",
    "\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct query with retrival of sources\n",
    "query = \"I want to find a place where I get a lot of stores nearby\"\n",
    "source_information = get_search_result(query, collection)\n",
    "combined_information = (\n",
    "    f\"Query: {query}\\nAccording to the results, suggest the best place in response to the query:\\n{source_information}.\"\n",
    ")\n",
    "\n",
    "print(combined_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "# CPU Enabled uncomment below üëáüèΩ\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\")\n",
    "# GPU Enabled use below üëáüèΩ\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensors to GPU\n",
    "input_ids = tokenizer(combined_information, return_tensors=\"pt\").to('cuda')\n",
    "response = model.generate(**input_ids, max_new_tokens=500)\n",
    "print(tokenizer.decode(response[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
